{
    "collab_server" : "",
    "contents" : "library(plyr)\nlibrary(sqldf)\nlibrary(cluster) \nlibrary(dbscan)\n\nN <- 1500\n\ndata <- read.csv('/Users/ramya/Documents/SMU/QTW/Week1/CaseStudy6_2/docword.nips.txt',sep = ' ', skip=3, header=F)\ncolnames(data) <- c(\"doc\",\"word\", \"count\")\nhead(data, n=10)\n\n#Creating column tf and calculating the value for tf as ln(1+count)\ndata$tf <- log(1+data$count)\nhead(data, n=10)\n\n#Calculate n value --> number of times a word appeared in all documents(across docs)\nnCount <- count(data, \"word\")\nhead(nCount, n=10)\n\n#Calculate idf for each word and assign it to new data frame 'idfData'\nnCount$idf <- log(1 + (N/nCount$freq))\nhead(nCount, n=10)\nidfData <- nCount\nhead(idfData, n=10)\n\ntfidfdata <- merge(x = data, y = idfData, by = \"word\", all = TRUE)\nhead(tfidfdata, n=10)\n\n#Calculate tf-idf scores per word per doc\ntfidfdata$tfIdf <- tfidfdata$tf*tfidfdata$idf\nhead(tfidfdata,n=10)\n\n#Assign final matrix to tfidfData\ntfidfData2 <- tfidfdata[c(1,2,4,6,7)]\nhead(tfidfData2, n=10)\n\ntfidfDatafinal <- tfidfData2[c(1,2,5)]\nhead(tfidfDatafinal, n=10)\n\n#kmeans with 5 clusters\nset.seed(20)\nclusters <- kmeans(tfidfDatafinal, 5)\n\n# Save the cluster number in the dataset as column 'Borough'\ntfidfDatafinal$kcluster <- as.factor(clusters$cluster)\nhead(tfidfDatafinal, n=10)\n\ntfidfDatafinal2 <- tfidfDatafinal[c(1,2)]\nhead(tfidfDatafinal2, n=10)\nstr(clusters)\n\n# vary parameters for most readable graph\n\nclusplot(tfidfDatafinal2, clusters$cluster, color=TRUE, shade=TRUE, \n         labels=2, lines=0)\n\n#kmeans with 10 clusters\nset.seed(10)\nclusters1 <- kmeans(tfidfDatafinal, 5)\ntfidfDatafinal2 <- tfidfDatafinal[c(1,2)]\nhead(tfidfDatafinal2, n=10)\nclusplot(tfidfDatafinal2, clusters$cluster, color=TRUE, shade=TRUE, \n         labels=2, lines=0)\n\n#future use\nlibrary(cluster)\nlibrary(HSAUR)\ndata(pottery)\nkm    <- kmeans(pottery,3)\ndissE <- daisy(pottery) \ndE2   <- dissE^2\nsk2   <- silhouette(km$cl, dE2)\nplot(sk2)\n\n#Running with test data\ntfidfTestdata <- tfidfDatafinal[c(1,2)]\ntail(tfidfTestdata, n=10)\n\n#DBSCAN\n## find suitable eps parameter using a k-NN plot for k = dim + 1\n## Look for the knee!\n#References: https://en.proft.me/2017/02/3/density-based-clustering-r/\n#https://www.rdocumentation.org/packages/dbscan/versions/1.1-2/topics/dbscan\nkNNdistplot(tfidfTestdata, k = 3)\nabline(h=.5, col = \"red\", lty=2)\n\nset.seed(1234)\nres <- dbscan(tfidfTestdata, eps = 3, minPts = 3)\nhullplot(tfidfTestdata, res$cluster)\n\nmax(res$cluster)\npairs(iris, col = res$cluster + 1L)\n\n\n#Creating histogram\n\nhist(tfidfdata$count, \n     main=\"Histogram for words\", \n     xlab=\"Count\", \n     xlim=c(0,135),\n     border=\"blue\", \n     col=\"green\",\n     breaks=50)\n\nhist(tfidfdata$tfIdf, \n     main=\"Histogram for words\", \n     xlab=\"Count\", \n     xlim=c(0,33),\n     border=\"blue\", \n     col=\"green\",\n     breaks=20)\n\n#word cloud testing \ninstall.packages(\"tm\")  # for text mining\ninstall.packages(\"SnowballC\") # for text stemming\ninstall.packages(\"wordcloud\") # word-cloud generator \ninstall.packages(\"RColorBrewer\") # color palett\n\nlibrary(\"tm\")\nlibrary(\"SnowballC\")\nlibrary(\"wordcloud\")\nlibrary(\"RColorBrewer\")\n\ndataTxt <- read.csv('/Users/ramya/Documents/SMU/QTW/Week1/CaseStudy6_2/vocab.nips.txt',header=F)\ncolnames(dataTxt) <- c(\"wordtext\")\nhead(dataTxt, n=10)\n\ndataTxt2 <-dataTxt\n\ntfidfdata\ninspect(dataTxt)\n\ndataTxt2$word <- seq.int(from=1, to=12419, by=1)\ntfidfdata3<-tfidfdata\ndataTxtFinal <- merge(x = tfidfdata3, y = dataTxt2, by = \"word\", all = FALSE)\n\nhead(dataTxtFinal, n=10)\n\nclouddata <- dataTxtFinal[dataTxtFinal$doc == 1,]\n\nhist(clouddata$freq, \n     main=\"Histogram for words\", \n     xlab=\"Words\", \n     border=\"blue\", \n     col=\"green\",\n     breaks=20)\n\nset.seed(1234)\nwordcloud(words = clouddata$wordtext, freq = clouddata$freq, min.freq = 110,\n          max.words=150, random.order=FALSE, rot.per=0.35, \n          colors=brewer.pal(8, \"Dark2\"))\n\n\n#word cloud on kmeans 10\nset.seed(10)\nclusters1 <- kmeans(tfidfDatafinal, 10)\ntfidfDatafinal4 <- tfidfDatafinal\n\n\ntfidfDatafinal4$kcluster <- as.factor(clusters1$cluster)\nhead(tfidfDatafinal4, n=10)\ntail(tfidfDatafinal4, n=10)\n\ndataTxtFinal <- merge(x = tfidfDatafinal4, y = dataTxt2, by = \"word\", all = FALSE)\nhead(dataTxtFinal)\n\n#typeof(tfidfDatafinal4$kcluster)\ntfidfDatafinal4$kcluster<- as.numeric(tfidfDatafinal4$kcluster)\nhist(tfidfDatafinal4$kcluster, \n     main=\"Hist\", \n     xlab=\"clusters\", \n     border=\"blue\", \n     col=\"green\",\n     breaks=10)\n\ncount1 <- count(tfidfDatafinal4, \"word\")\ncount1<- count1[order(-count1$freq),]\nhead(count1, n=10)\n\ndataTxtFinal2 <- merge(x = count1, y = dataTxtFinal, by = \"word\", all = FALSE)\nhead(dataTxtFinal2, n=10)\n\ndataTxtFinal5 <- dataTxtFinal\nhead(dataTxtFinal5, n=10)\ntail(dataTxtFinal5, n=10)\n\n#appending kcluster column to the dataset\ndataTxtFinal5$kcluster <- tfidfDatafinal4$kcluster\nhead(dataTxtFinal5, n=10)\n\nclouddata <- dataTxtFinal4[dataTxtFinal4$kcluster == 5,]\ntail(clouddata, n=10)\nhist(clouddata$freq, \n     main=\"Histogram for words\", \n     xlab=\"words\", \n     border=\"blue\", \n     col=\"green\",\n     breaks=20)\n\ncount1 <- count(clouddata, \"word\")\ncount1<- count1[order(-count1$freq),]\n\n\ndataTxtcloud <- merge(x = count1, y = dataTxt2, by = \"word\", all = FALSE)\ndataTxtcloud<- dataTxtcloud[order(-dataTxtcloud$freq),]\nhead(dataTxtcloud,n=30)\n\n\nset.seed(12345)\nwordcloud(words = dataTxtcloud$wordtext, freq = dataTxtcloud$freq, min.freq = 178000,\n          max.words=35, random.order=FALSE, rot.per=0.35, \n          colors=brewer.pal(8, \"Dark2\"))\n\ntypeof(tfidfDatafinal4$kcluster)\ntfidfDatafinal4$kcluster<- as.numeric(tfidfDatafinal4$kcluster)\nhist(tfidfDatafinal4$kcluster, \n     main=\"Hist\", \n     xlab=\"clusters\", \n     border=\"blue\", \n     col=\"green\",\n     breaks=10)\n\ncluster_words <- lapply(unique(clustering), function(x){rows <- dtm[ clustering == x , ]}\n",
    "created" : 1536856790126.000,
    "dirty" : false,
    "encoding" : "ASCII",
    "folds" : "",
    "hash" : "3802813381",
    "id" : "4BCC3A87",
    "lastKnownWriteTime" : 1536856732,
    "last_content_update" : 1536856732,
    "path" : "~/Documents/Ramesh/SMU/GitRepos/QTW/QuantifyingTheWorld_CS6/Week1/QTW_Casestudy6.R",
    "project_path" : "Week1/QTW_Casestudy6.R",
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}